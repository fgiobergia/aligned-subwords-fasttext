{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_vector(v, M, n = 1):\n",
    "    indices = np.flip(np.argsort(np.dot(M, v)))[:n]\n",
    "    return indices[0] if n == 1 else indices\n",
    "\n",
    "def print_examples(starting_language, target_language, word): \n",
    "    idx = find_closest_vector(starting_language[word], target_language.vectors)\n",
    "    result = target_language.index_to_key[idx]\n",
    "    #print(starting_language.has_index_for(word), result, idx)\n",
    "    return result\n",
    "\n",
    "# make a function that taken a word, it generates all the words that are the same but with every letter of the alphabet added at the beginning, then in the middle, then at the end \n",
    "\n",
    "def generate_words(word):\n",
    "    words = []\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = c + word\n",
    "        words.append(new_word)\n",
    "\n",
    "    mid = len(word) // 2\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word[:mid] + c + word[mid:]\n",
    "        words.append(new_word)\n",
    "\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word + c\n",
    "        words.append(new_word)\n",
    "    return words\n",
    "\n",
    "\n",
    "# make a function that given a list of words, return for each word the closest word in the target language \n",
    "\n",
    "def find_closest_words(starting_language, target_language, words):\n",
    "    results = []\n",
    "    for word in words:\n",
    "        results.append(print_examples(starting_language, target_language, word))\n",
    "    return results\n",
    "\n",
    "def split_vector(v, n):\n",
    "    return np.array_split(v, n)\n",
    "\n",
    "# split the vector of results in three subvectors of the same length \n",
    "def noise_experiment(starting_language, target_language, word):\n",
    "    res = find_closest_words(starting_language, target_language, generate_words(word))\n",
    "    temp = split_vector(res, 3)\n",
    "\n",
    "    print(len(temp[0]), len(temp[1]), len(temp[2]))\n",
    "    # return the number of each word for the subvectors ordered by their frequency\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(temp)):\n",
    "        values, counts = np.unique(temp[i], return_counts=True)\n",
    "        ordered_indexes = np.argsort(-counts)\n",
    "        results.append((values[ordered_indexes], counts[ordered_indexes]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heron_path = \"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/\"\n",
    "print(\"loading italian vectors\")\n",
    "ita_aligned = KeyedVectors.load_word2vec_format(f\"wiki.it.align.vec\")\n",
    "print(\"loading english vectors\")\n",
    "eng_aligned = KeyedVectors.load_word2vec_format(f\"wiki.en.align.vec\")\n",
    "#ita_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.it.bin\") \n",
    "#eng_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.en.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look if the normal words are aligned with the same words of fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading italian vectors\n",
      "loading english vectors\n",
      "loading portuguese vectors\n"
     ]
    }
   ],
   "source": [
    "lang = \"it\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading italian vectors\")\n",
    "with open(f\"wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    ita_new = pickle.load(f)\n",
    "\n",
    "lang = \"en\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading english vectors\")\n",
    "with open(f\"wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    eng_new = pickle.load(f)\n",
    "\n",
    "lang = \"pt\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading portuguese vectors\")\n",
    "with open(f\"wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    pt_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('casa', 228)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], ita_aligned.vectors)\n",
    "\n",
    "ita_aligned.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vector, find in a matrix the closest vector to it\n",
    "# VALUTA DI USARE get_vector() per ottenere il vettore di una parola\n",
    "\n",
    "idx = find_closest_vector(ita_new[\"ciao\"], eng_new.vectors)\n",
    "idx2 = find_closest_vector(ita_new[\"ciao\"], eng_aligned.vectors)\n",
    "eng_new.index_to_key[idx], idx, eng_aligned.index_to_key[idx2], idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"gatto\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"papero\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_aligned[\"ciao\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"casa\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx) \n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"gatto\"], eng_aligned.vectors)   \n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"papero\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words with typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False tomato 16956\n"
     ]
    }
   ],
   "source": [
    "word = \"pomodoriniq\"\n",
    "\n",
    "print_examples(ita_new, eng_new, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alberello 79967\n",
      "False tree 1664\n"
     ]
    }
   ],
   "source": [
    "word = \"alberelo\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], ita_new.vectors)\n",
    "key = ita_new.index_to_key[idx]\n",
    "print(key, idx)\n",
    "idx = find_closest_vector(ita_new[key], eng_new.vectors)\n",
    "print(ita_new.has_index_for(word), eng_new.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "soulamea\n",
      "swae\n",
      "kekenboschia\n",
      "amboro\n",
      "noega\n",
      "caribbeana\n",
      "albanyana\n",
      "waina\n",
      "paniola\n",
      "loranga\n"
     ]
    }
   ],
   "source": [
    "word = \"albero\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], ita_new.vectors)\n",
    "key = ita_new.index_to_key[idx]\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors, 10)\n",
    "print(ita_new.has_index_for(word))\n",
    "print()\n",
    "for i in idx: \n",
    "    print(eng_new.index_to_key[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elephant -> Elefante -> Elefant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elefante', 'elefanten'], dtype='<U10'),\n",
       "  array([25,  1], dtype=int64)),\n",
       " (array(['akun', 'xbj', 'wami', 'varu', 'umari', 'tkv', 'tawe', 'sohatu',\n",
       "         'slokar', 'sku', 'shaji', 'ranvir', 'pagal', 'oot', 'malla',\n",
       "         'khri', 'fÃ´n', 'elefante', 'dhar', 'bhu', 'aset', 'arpaso',\n",
       "         'aphur', 'allÂ»', 'ÐºÐ°ÑÐ»', 'ê³ ê°'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['elefante', 'elefantide', 'elefanten', 'elefanti', 'elephanta'],\n",
       "        dtype='<U10'),\n",
       "  array([14,  6,  2,  2,  2], dtype=int64))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"elephant\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elefant', 'elefante'], dtype='<U10'), array([22,  4], dtype=int64)),\n",
       " (array(['kaula', 'kir', ',ai', 'vavÃ³', 'supah', 'suf', 'sika',\n",
       "         'quincannon', 'mukia', 'melaka', 'magech', 'kosti', 'khak', 'ka',\n",
       "         'hihi', 'gady', 'bhandari', 'akshak', 'ajaka', 'aei', '/la', '/en',\n",
       "         'Î¼j', 'ìë'], dtype='<U10'),\n",
       "  array([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['elefant', 'elefantes', 'elefanta', 'elefante', 'elephas'],\n",
       "        dtype='<U10'),\n",
       "  array([17,  4,  3,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"elephant\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elephant'], dtype='<U10'), array([26], dtype=int64)),\n",
       " (array(['>la', 'è§', 'å°ä¸', 'âmar', 'ÏÏÎ»Î±', 'Î³Î¯Î³Î±Ï', 'Î±Î½Ï', 'ÉÅ', 'Ã¬l',\n",
       "         'yeia', 'toÅ', 'terion', 'synes', 'oneia', 'oino', 'nsdnld', 'ndo',\n",
       "         'myrion', 'molou', 'lÌ©', 'kaloula', 'ergenia', 'ekdikitho',\n",
       "         'athinoula', 'é', '\\uf06e'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['elephant', 'elephanten'], dtype='<U10'),\n",
       "  array([25,  1], dtype=int64))]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"elefante\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elefante', 'elefantinho', 'elefanta'], dtype='<U11'),\n",
       "  array([18,  7,  1], dtype=int64)),\n",
       " (array(['alaÃ´r', 'ÎºÎ­ÏÎºÏÏÎ±', 'ÎµÎ»ÎµÏÎ¸ÎµÏÎ¯Î±', 'zÃ³tico', 'svaÃ°ilfari', 'sirene',\n",
       "         'ratatoskr', 'pÃ­rrica', 'posÃ­vel', 'paymaster', 'particpante',\n",
       "         'ortÃ­gia', 'ne~e', 'mÃ­cala', 'molÃ³ssia', 'imitador', 'haliaeetus',\n",
       "         'fsfla', 'enÃ©ade', 'egÃ­alo', 'dÃ­on', 'cacÃ³fato', 'batlha',\n",
       "         'babaca', 'Ø·Ø±Ø§Ø¨ÙØ³', 'éè²ã®ã¬ãã·ã¥ãã«'], dtype='<U11'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['elefant', 'elefante', 'elefanten', 'elefanta', 'elefantes'],\n",
       "        dtype='<U11'),\n",
       "  array([12, 10,  2,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"elefante\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elephant'], dtype='<U10'), array([26], dtype=int64)),\n",
       " (array(['#og', 'Ù¤', 'Ïf', 'Î¶ÏÎ·', '}â¥', 'tÃ¼t', 'tyua', 'tieion', 'rate}}',\n",
       "         'poper', 'ogn', 'lioni', 'lefta', 'kyllene', 'ihnc', 'heracle',\n",
       "         'gadara', 'ezzie', 'avator', 'amatue', 'aegp', '>ho', '+#',\n",
       "         '%omitted%', 'à¦¯à§à¦¬', 'âmet'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['elephant', 'elephants', 'elephanten'], dtype='<U10'),\n",
       "  array([23,  2,  1], dtype=int64))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"elefante\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['elefante'], dtype='<U29'), array([26], dtype=int64)),\n",
       " (array(['bÃ¨nna', 'pumminale', '#bbbbbe', 'Î»ÏÏÎ±', 'Î´Î·Î¼Î®ÏÎ·Ï',\n",
       "         'videogioco/film/libro/fumetto', 'trampy', 'rotolante',\n",
       "         'rivoltoso', 'puliero', 'nausimedonte', 'megasound', 'matunata',\n",
       "         'm/v', 'j/p', 'hafenkante', 'guerriero/bolero', 'fedala',\n",
       "         'controassicurazione', 'ciclopentolato', 'bÅ«lÄq', 'afflante',\n",
       "         'á¼Î½Î´ÏÏÏ', 'ä¼è©±'], dtype='<U29'),\n",
       "  array([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['elefanti', 'elefante', 'elefant', 'elefanten', 'elefantide',\n",
       "         'elefantina'], dtype='<U29'),\n",
       "  array([11, 10,  2,  1,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"elefante\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple -> Mela -> MaÃ§Ã£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['babbler', '/apple', 'tix', 'ssop', 'pymble', 'puledro', 'pix',\n",
       "         'pimple', 'orv', 'omputing', 'nutt', 'mouseup', 'marmell',\n",
       "         'mapple', 'madin', 'lappo', 'hopple', 'gobble', 'flitt',\n",
       "         'fingerboard', 'erby', 'broccolo', 'weedy', 'zapple'], dtype='<U11'),\n",
       "  array([3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['/doc', 'xpression', 'xmi', 'wiki@home', 'vob', 'ugc', 'tkv',\n",
       "         'servator', 'pout', 'pns', 'nÄnÄ', 'nswp', 'nee', 'mÄlÄ', 'markan',\n",
       "         'lgu', 'iind', 'iat', 'ddj', 'daal', 'chapero', 'bucy', 'ammalato',\n",
       "         'agbu', 'zvezde', 'ÏÎµ'], dtype='<U11'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['apple', 'hackberry', 'acorus', 'mele', 'marshmallow', 'kempston',\n",
       "         'ider', 'frish', 'egeskov', 'cydia', 'bracker', 'aros', 'applet',\n",
       "         'apperson', 'amarok', 'orx', 'vinx'], dtype='<U11'),\n",
       "  array([9, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"apple\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['snapple', 'apple', 'dapple', 'treach', 'squeezebox', 'scrapple',\n",
       "         'rappaport', 'pownall', 'pegan', 'odp', 'noblett', 'murcho',\n",
       "         'mtabletools', 'lapp', 'fulvo', 'cocoa', 'caswell', 'caskey',\n",
       "         'beanshell', 'vinn', 'wintry'], dtype='<U11'),\n",
       "  array([4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        dtype=int64)),\n",
       " (array(['vob', 'thoi', '#nome', 'z/', 'xpert', 'wikiwix', 'vlis', 'vierde',\n",
       "         'purinsesu', 'planeten', 'nle', 'navigateurs', 'morreu', 'mje',\n",
       "         'labview', 'jcl', 'hif', 'grc', 'dde', 'cre', 'ceru', 'alguidÃ¡',\n",
       "         'zongo', 'Ã´m'], dtype='<U11'),\n",
       "  array([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['apple', 'dapple', 'applet', 'appletree', 'beans', 'cerejas',\n",
       "         'citrix', 'colca', 'colvillea', 'gingerbread', 'hedegaard',\n",
       "         'hillingdon', 'kappler', 'tix', 'twix', 'whoami'], dtype='<U11'),\n",
       "  array([9, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"apple\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['#ela', 'vihta', 'taveiro', 'stachyris', 'phina', 'nsaliwa',\n",
       "         'mfutila', 'lÃ¶g', 'kudina', 'kgph', 'kajona', 'Él', 'jÃ¤mejala',\n",
       "         'essÃ¤', 'emela', 'ejal', 'dssu', 'aqvr', 'agrilina', 'add_text',\n",
       "         'abiana', '#vela', '#mint', 'gerka', 'é»é'], dtype='<U9'),\n",
       "  array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=int64)),\n",
       " (array(['adda', 'unilazer', 'ukhuwah', 'ratnu', 'plaÄem', 'pirlita',\n",
       "         'peÄat', 'paalma', 'mmma', 'meÅe', 'meyla', 'meola', 'menla',\n",
       "         'meala', 'karadjova', 'ipalapa', 'femra', 'efla', 'dhela', 'dehmi',\n",
       "         'cuyana', 'chÃ¢tain', 'brayeux', 'alila', 'uzet', 'zsye'],\n",
       "        dtype='<U9'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['#ash', 'sauvelade', 'qedar', 'omato', 'naame', 'melax', 'melas',\n",
       "         'melar', 'melan', 'medun', 'malat', 'konae', 'kelil', 'kahma',\n",
       "         'ibil', 'ghah', 'elav', 'elau', 'elai', 'diomedes', 'bajeli',\n",
       "         'axan', 'agalah', '`b`', 'selab', 'âisle'], dtype='<U9'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"mela\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['/xp', 'tjÃ¤ngvide', 'skÃ¤rholmen', 'semora', 'sambabaca', 'ravula',\n",
       "         'quiÃ©reme', 'pt&lr', 'proenca', 'nmea', 'muniadona', 'matauatu',\n",
       "         'kÃ¤ina', 'keulla', 'kapenga', 'iÃµla', 'ipala', 'heikkila',\n",
       "         'haaparanta', 'gÅÃ³wna', 'chalybea', 'celeneh', 'botox', 'bitupitÃ¡',\n",
       "         'Ã¶deshÃ¶g', 'Å¡imeÄek'], dtype='<U18'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['arzÃº', 'woevre', 'vocalviolÃ£o', 'tiÅ¡ina', 'tiye', 'slitaz',\n",
       "         'sikandra', 'saraghina', 'sabika', 'moapa', 'marijana', 'laperche',\n",
       "         'kirui', 'kayzer', 'jÃ¤rna', 'ihgal', 'hawza', 'harina', 'goÃ¨s',\n",
       "         'chilapa', 'casalinhos', 'berghaus', 'baÅar', 'baraom', 'wrÃ³bel',\n",
       "         'ÅÄ±kÄ±dÄ±m'], dtype='<U18'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['tsafrir', 'adhamiyah', 'tanios', 'studiocanalworking', 'roumois',\n",
       "         'repolhos', 'naama', 'midrash', 'meyhna', 'mepe', 'meneu',\n",
       "         'meliae', 'melax', 'melan', 'maroantsetra', 'kymyz', 'karÃª',\n",
       "         'glucocorticÃ³ides', 'gilad', 'elah', 'danelaw', 'bananafish',\n",
       "         'arÃ¡clovo', 'melas', 'vÃ­grÃ­Ã°r'], dtype='<U18'),\n",
       "  array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"mela\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['apple', 'oidb', 'raspberry', 'actvity', 'Î½ÎµÏÎ¬', 'Ã¤pple', 'znb',\n",
       "         'zfq', 'water_', 'sweeta', 'svbv', 'pyt', 'mmbl', 'infa', 'glob',\n",
       "         'egÂ£', 'daec', 'aquafish', 'allusia', 'à¶à·à¶«', 'åå°¼'], dtype='<U11'),\n",
       "  array([4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        dtype=int64)),\n",
       " (array(['#mir', 'uneh', 'tular', 'tammara', 'stripe', 'sozopetra', 'rinho',\n",
       "         'ndimbati', 'meÅeu', 'lmap', 'lamarckian', 'khreyn', 'kalakat',\n",
       "         'kadozeik', 'hulah', 'flava', 'fabÃ³', 'dÉ', 'cierno', 'cichla',\n",
       "         'ceiÃ§a', 'beecheyi', 'avÄ±', 'agall', 'Ã¥Â³', 'åæ¥­'], dtype='<U11'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['#bread', 'ê²ë§', 'ç²', 'ä¼¯æ¨', 'ã¾ã', 'â¹yâº', 'âcut', 'à²¶à³',\n",
       "         'vermelhinho', 'souse', 'sieiro', 'savÃ³ia', 'rootin', 'prunes',\n",
       "         'prugne', 'pot,', 'kÃ¶la', 'hawberries', 'halvas', 'cocore',\n",
       "         'christkind', 'barme', 'apples', '#chick', 'ë°ë¬¼ê´', 'í¨ë°ë¦¬'],\n",
       "        dtype='<U11'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"maÃ§Ã£\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['melagrana', 'supernazione', 'sunchild', 'starquake', 'soaco',\n",
       "         'raspberry', 'pear', 'obdotta', 'moonchild', 'mielata', 'metafora',\n",
       "         'trÃ¤det', 'airflow', 'imbalsamazione', 'icedtea', 'gelatina',\n",
       "         'g+c', 'fragoletta', 'firnificazione', 'cornflake',\n",
       "         'autocompilazione', 'animazione', 'anguria', 'lattica', 'vbnc'],\n",
       "        dtype='<U16'),\n",
       "  array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=int64)),\n",
       " (array(['alamgiri', 'superdurezza', 'slÃ¶ngvir', 'shabranigdu',\n",
       "         'seccoborella', 'pemmican', 'patÃ¨', 'parahybana', 'misÃ ', 'minÃ¹',\n",
       "         'mappatura', 'makrana', 'lamarckiani', 'kukufeldia', 'jayasekera',\n",
       "         'hurriti', 'horridula', 'goytisolo', 'ciadra', 'canditatura',\n",
       "         'calzettone', 'blockfÃ¼hrer', 'baá¸¥r', 'baÃ§o', 'yanfolila', 'å£å¥³å­©'],\n",
       "        dtype='<U16'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['#Ã©', 'ÏÎ­Î¼Î½Ï', 'zucche', 'washbond', 'tagliata', 'sfincia',\n",
       "         'sermenza', 'salume,', 'pÃ¹Ã²', 'pinocchia', 'papÃ©e', 'occazione',\n",
       "         'mielata', 'manÂ·ga', 'mangiarselo', 'maluco', 'maccheronata',\n",
       "         'kÃ¼rtÅskalÃ¡cs', 'gianda', 'garofano', 'ciliegia', 'capretto',\n",
       "         'briaco', 'asÅgi', 'â', 'é'], dtype='<U16'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"maÃ§Ã£\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Butterfly -> Farfalla -> Borboleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['farfalla', 'butterfly', 'glaucopsyche', 'ildiscobolo', '$this',\n",
       "         '/cosa', 'ndingi'], dtype='<U12'),\n",
       "  array([17,  2,  2,  2,  1,  1,  1], dtype=int64)),\n",
       " (array(['blabber', 'tanase', 'synephebi', 'stalo', 'scha', 'pelz', 'ooi',\n",
       "         'newstead', 'klei', 'kimo', 'joger', 'hillz', 'heeeeere',\n",
       "         'gymnobucco', 'grilla', 'gambus', 'fr/de', 'fotter', 'flammer',\n",
       "         'figona', 'farfallone', 'farfalla', 'corner', 'cherina',\n",
       "         'wildgravio', 'Ð´Ð±'], dtype='<U12'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['farfalla', 'glaucopsyche', 'farfalline', 'kipod'], dtype='<U12'),\n",
       "  array([19,  5,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"butterfly\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['borboleta', 'stutterfly', 'butterfly', 'knode'], dtype='<U15'),\n",
       "  array([17,  6,  2,  1], dtype=int64)),\n",
       " (array(['#emma', 'stunna', 'stiletto', 'scylax', 'schickele', 'scarus',\n",
       "         'rÃ¡cz', 'rufoniger', 'rhomb', 'omele', 'mÃ¶rch', 'knochen',\n",
       "         'hysterica', 'honeyeater', 'holler', 'helvola', 'ferax', 'cocco',\n",
       "         'cerkno', 'buzau', 'buchholzi', 'botamo', 'bardach', 'agathocles',\n",
       "         'stutterfly', 'zella'], dtype='<U15'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['borboleta', 'gempylus', 'borboletinha', 'butterflycorner',\n",
       "         'cupid', 'kaempferia', 'melax', 'whax'], dtype='<U15'),\n",
       "  array([18,  2,  1,  1,  1,  1,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"butterfly\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['butterfly', 'gutterfly', 'photoperiod'], dtype='<U11'),\n",
       "  array([22,  3,  1], dtype=int64)),\n",
       " (array(['tegi', 'abbod', 'ææ', 'å¸', 'Ø', 'Ã¶rfi', 'zacca', 'widd', 'waati',\n",
       "         'viminia', 'timbur', 'é°å¥', 'plectro', 'ndua', 'mullina', 'maysa',\n",
       "         'lugna', 'llamp', 'gullfoss', 'grami', 'cymm', 'cethar', 'bedd',\n",
       "         'neesa', 'éº»éå­'], dtype='<U11'),\n",
       "  array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=int64)),\n",
       " (array(['butterfly'], dtype='<U11'), array([26], dtype=int64))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"farfalla\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['mariposa/borboleta', 'borboleta'], dtype='<U22'),\n",
       "  array([22,  4], dtype=int64)),\n",
       " (array(['abenÃ§oasse', 'streoneshalh', 'sjÃ¶jungfrun', 'paiâ¦', 'orthia',\n",
       "         'ondimba', 'maÃ­llo', 'jÃ¡rnsaxa', 'go/under',\n",
       "         'femininopb/andebolpe', 'faraona', 'evanora', 'elayirampannai',\n",
       "         'crispa', 'citreola', 'cellador', 'carruthersi', 'brigÃ°i',\n",
       "         'bolimbolacho', 'bipinnula', 'bernau_breitscheidstr_', 'batlha',\n",
       "         'allbÃ¤ck', 'aleivosa', 'taghrout', 'Ø´ÙØ®'], dtype='<U22'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['borboleta', 'astyoche', 'foecundatrix', 'mariposa/borboleta'],\n",
       "        dtype='<U22'),\n",
       "  array([23,  1,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"farfalla\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['farfalla', 'farfallina'], dtype='<U13'),\n",
       "  array([25,  1], dtype=int64)),\n",
       " (array(['dafrosa', 'spante', 'siapiccia', 'semiflava', 'seccoborella',\n",
       "         'santafusca', 'pozarica', 'polarografica', 'pirÂ²', 'pioggerellina',\n",
       "         'miÃ±arro', 'marirosa', 'luccketta', 'lanzahÃ­ta', 'l`unica',\n",
       "         'guttula', 'granatino', 'granatina', 'galetta', 'fialetta',\n",
       "         'faÃ­sca', 'doletta', 'diglio', 'deflatore', 'versicolora',\n",
       "         'Å¡alina'], dtype='<U13'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['farfalla', 'farfalle', 'chrysomelinae'], dtype='<U13'),\n",
       "  array([23,  2,  1], dtype=int64))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"borboleta\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['butterfly'], dtype='<U11'), array([26], dtype=int64)),\n",
       " (array(['#cska', '#cada', 'sisterna', 'seå¹³', 'pudorella', 'prilla',\n",
       "         'plectrura', 'pistoli', 'pepta', 'montela', 'kunka', 'inkcap',\n",
       "         'dusta', 'cremastra', 'chepinoga', 'butterfly', 'asoleni',\n",
       "         'agarita', '$â', '#puna', '#eta', '#crazy', 'velena', 'ì²­'],\n",
       "        dtype='<U11'),\n",
       "  array([3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['butterfly', 'butterflies'], dtype='<U11'),\n",
       "  array([25,  1], dtype=int64))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"borboleta\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat -> Gatto -> Gato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['ccat', 'acat', 'tsf', 'tribunal', 'tix', 'sottocategoria', 'scat',\n",
       "         'pkg', 'oms', 'nsm', 'monobox', 'lmn', 'lcat', 'kcat', 'jct',\n",
       "         'iiop', 'icat', 'fcat', 'esecutivitÃ ', 'ecat', 'cgg', 'analingus',\n",
       "         'vnx', 'zcat'], dtype='<U14'),\n",
       "  array([3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['/dev/hd', 'sysop', 'stemma', 'shvat', 'sgp', 'rosc', 'nter',\n",
       "         'nib', 'miniacea', 'marocchina', 'isme', 'ial', 'ftu', 'dehm',\n",
       "         'czy', 'cuera', 'csat', 'cisac', 'chat', 'ceat', 'ccat', 'cbv',\n",
       "         'br/index', 'an/', 'tvl', 'á'], dtype='<U14'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['atf', 'scu', 'probyn', 'ppy', 'piperonil', 'phbh', 'nex', 'myd',\n",
       "         'macc', 'lnk', 'gatti', 'ftu', 'fttx', 'espera', 'coatl', 'cmp',\n",
       "         'cim', 'cesvi', 'caty', 'catu', 'cato', 'cath', 'cate', 'camelli',\n",
       "         'telem', 'xpb'], dtype='<U14'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"cat\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['dcat', 'kcat', 'fcat', 'capes', 'uw', 'scat', 'redirec', 'lcat',\n",
       "         'ipfix', 'ipf', 'icg', 'icat', 'icap', 'icann', 'fdh', 'fct',\n",
       "         'fap', 'escolaridade', 'ciat', 'ccs', 'categorize', 'xac', 'xsl'],\n",
       "        dtype='<U12'),\n",
       "  array([2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1], dtype=int64)),\n",
       " (array(['aaj', 'tnef', 'sysop', 'rbe', 'qaq', 'pold', 'peziza', 'inp',\n",
       "         'iet', 'idc', 'huapango', 'hekat', 'hayy', 'gtm', 'fpe', 'efqm',\n",
       "         'csat', 'chat', 'cepae', 'ccs', 'ccpg', 'cbat', 'brasÃ£o',\n",
       "         'argelino', 'tÃ©lÃ©', 'wijs'], dtype='<U12'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['botella', 'uidoc', 'tezcatl', 'telemedia', 'tany', 'sewell',\n",
       "         'playtone', 'mungo', 'lactiflora', 'keira', 'jtf', 'gpio', 'gatos',\n",
       "         'dcn', 'cpe', 'cooc', 'cbp', 'catu', 'cato', 'cati', 'cath', 'cat',\n",
       "         'cabr', 'brr', 'unfpa', 'xqt'], dtype='<U12'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"cat\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['pottore', 'dlisti', '#mouse', 'tootle', 'sulmoni', 'stimate',\n",
       "         'puleng', 'puffi', 'peggit', 'nekomaru', 'guÄ¾a', 'gryll', 'gippo',\n",
       "         'fabin', 'dictis', 'checchio', 'carichini', 'buffoni',\n",
       "         'beaglebone', 'avarolli', ',Â½', '#ugo', 'å', 'é°å¥'], dtype='<U10'),\n",
       "  array([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['#tot', 'æ¬ã®æ³ç¤¾', 'ãã¿ã', 'Ê', 'Ç­', 'Æ', 'vignate', 'sqay', 'smalli',\n",
       "         'sinjoro', 'serd', 'rotner', 'opÄine', 'muntanyola', 'miolo',\n",
       "         'jantti', 'idey', 'hyoh', 'glci', 'eggther', 'dag', 'comerÃ¡s',\n",
       "         'beltri', 'bejgli', 'æ°¸æ', 'ç²'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['cat', '#chick', '}Å', 'rosov', 'pig', 'nyan', 'mory', 'lungleg',\n",
       "         'klÃ¦ngur', 'kitten', 'grumpig', 'flewell', 'ducku', 'doglion',\n",
       "         'crabbit', 'chimpy', 'chimplee', 'chimpa', 'buford', 'bootin',\n",
       "         '#pn', '#og', '#cow', 'à³©', 'è¯'], dtype='<U10'),\n",
       "  array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"gatto\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['luciaccoelho', 'animago', 'vanzi', 'vanhoye', 'ursolino', 'urso',\n",
       "         'tribble', 'stozice', 'saci', 'pessagno', 'oldroyd', 'merlino',\n",
       "         'loquasto', 'frsa', 'frassilongo', 'folivora', 'fantascienza',\n",
       "         'edilcuoghi', 'dalcio', 'bicci', 'beeblebrox', 'wallago', 'wolo'],\n",
       "        dtype='<U19'),\n",
       "  array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1], dtype=int64)),\n",
       " (array(['autografo', 'vikedal', 'uffugo', 'taladro', 'seninho', 'sallo',\n",
       "         'saliento', 'sabÃ to', 'reizinho', 'raiano', 'nesma', 'maÃ­llo',\n",
       "         'mataskelekele', 'lusÃ³/Ã´fona', 'iÂ´ve', 'izvoarele', 'fiwc',\n",
       "         'fedelho', 'etxebarria', 'diferenÃ§a_uct_verÃ£o', 'calÃ³gero',\n",
       "         'bokuto', 'bigdelete', 'bibino', 'Ã­ole', 'ç½ '], dtype='<U19'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['rato/mouse', 'cachorro', 'babbo', 'sturmeck', 'spunky',\n",
       "         'serelepe', 'sabichÃ£o', 'piriquito', 'picazzo', 'perninha',\n",
       "         'jumpstart', 'jogador/treinador', 'floquinho', 'fantasmino',\n",
       "         'crawdaddys', 'cottingley', 'cocksucker', 'chug', 'burnside',\n",
       "         'brÃ¨de', 'birdhouse', 'tchaicovsky', 'Ã¥l'], dtype='<U19'),\n",
       "  array([3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1], dtype=int64))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"gatto\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['&pb', 'Ç', '~to', 'unisono', 'tuzlu', 'tokunai', 'tioro',\n",
       "         'spingere', 'shound', 'oxl', 'opdivo', 'ofono', 'mmvr', 'miseno',\n",
       "         'liru', 'hpÃ¨', 'halcyone', 'froso', 'feletto', 'daioni', 'csâ',\n",
       "         'bl&srcid', 'axyi', 'ancoro', 'á¸¯', 'ì§ì¤'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['bÄru', 'æ ª', 'å¼ä»', '}Å', 'vando', 'ular', 'uccio', 'toak', 'talÃ¡n',\n",
       "         'shouto', 'shound', 'sento', 'seiho', 'piÈ', 'mÄka', 'moonland',\n",
       "         'hunk', 'hrÃ³Ã°ulfr', 'heno', 'galton', 'gaito', 'expended',\n",
       "         'energo', 'eext', 'é ', 'ì±'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['bagcal', 'ã', 'à¦°à¦¾à¦¤', 'Ähole', 'yoep', 'woolie', 'vykhlop',\n",
       "         'toyak', 'toper', 'tbpa', 'stinko', 'rancer', 'pochenko', 'hueu',\n",
       "         'honeybeast', 'haskey', 'gator', 'filmport', 'emon', 'draculon',\n",
       "         'dogs', 'dobash', 'crice', 'buppy', 'å¸', 'ï·¼'], dtype='<U10'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"gato\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['&sig', 'ÎºÎ»ÎµÎ¹Ï', 'vospro', 'trÃ¬nita', 'transcranico', 'tambÃ²',\n",
       "         'skeletron', 'serina/treonina', 'scodinzolante', 'rovarÃ¨',\n",
       "         'resa_vino', 'pucajirca', 'nicostene', 'neroccio',\n",
       "         'motocompressore', 'menuetto', 'kawasumi', 'idrossichinolina',\n",
       "         'gemini_', 'flio', 'faraualla', 'dolone', 'cantabile', 'bruscello',\n",
       "         'ÙÙØ±', 'æ¸æ°´'], dtype='<U16'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['arturiano', 'Ð¼Î¹ÑÑÑÑ', 'tentmaker', 'spesa', 'rospodotto',\n",
       "         'raposo', 'preyas', 'potÃ ', 'ozrock', 'otumbo', 'okaasan',\n",
       "         'nome_leftbar', 'muÅ¾iki', 'miÃ±arro', 'micidial', 'korpikoski',\n",
       "         'iante', 'guardsman', 'gnifone', 'galton', 'gaito', 'bernabucci',\n",
       "         'bailato', 'azmorigan', 'å±±', 'çµå'], dtype='<U16'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['boomer', 'tigger', 'taÊ»u', 'takiki', 'stiltskin', 'soyak',\n",
       "         'shocksquatch', 'redcap', 'ratnikov', 'puÊ»u', 'psycopath', 'pestÃ²',\n",
       "         'perchicot', 'milÃ¹', 'lupaster', 'latran', 'gold/duck', 'gatow',\n",
       "         'gator', 'flammifer', 'emocianine', 'cani', 'buffin', 'brÃ»lante',\n",
       "         'woodpile', 'Å¾ygalka'], dtype='<U16'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"gato\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['fotografia_', 'fotogr', 'fotografias'], dtype='<U13'),\n",
       "  array([16,  6,  4], dtype=int64)),\n",
       " (array(['fotografia_', 'fotografias', 'fotoit', 'fototecnica', 'photo/',\n",
       "         'spettroscopia', 'agd', 'fluorescenza', 'fotografien',\n",
       "         'nomografia', 'ografia', 'photoblog', 'photodo', 'photographing',\n",
       "         'photorec', 'raman'], dtype='<U13'),\n",
       "  array([6, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['fotogr', 'fotografia_'], dtype='<U13'),\n",
       "  array([25,  1], dtype=int64))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"photography\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['mb_photo', 'photo/', 'fotografia_', '//image', '/foto',\n",
       "         '/images/foto', 'cronofotografia', 'img_id', 'img_media_type',\n",
       "         'iphoto', 'photo', 'photobucket'], dtype='<U15'),\n",
       "  array([10,  4,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)),\n",
       " (array(['/cor', 'yabo', 'vakataka', 'upas', 'totok', 'tewa', 'statistiku',\n",
       "         'se/', 'pnu', 'nikaea', 'nampho', 'mgn', 'luong', 'lambang',\n",
       "         'kuru', 'kou', 'inao', 'ilayang', 'haita', 'gyala', 'fights',\n",
       "         'dafundo', 'baringo', 'bangt', 'yango', 'â¿'], dtype='<U15'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['fotogr', 'fotoit', 'fotos', 'photodo', 'foto', 'fotochimico',\n",
       "         'fotofex', 'fotoni', 'fotopoulos', 'fotosub', 'fotothek', 'photo/',\n",
       "         'photographing', 'photon'], dtype='<U15'),\n",
       "  array([4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"photo\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['fotografia\\xa0', 'fotografia', 'fotogravura', 'photographe',\n",
       "         'photographo'], dtype='<U14'),\n",
       "  array([21,  2,  1,  1,  1], dtype=int64)),\n",
       " (array(['fotometria', 'fotolitografia', 'colorimetria', 'encoding', 'fot',\n",
       "         'fotog', 'fotografia', 'fotoquÃ­mica', 'photobleaching',\n",
       "         'photografia'], dtype='<U14'),\n",
       "  array([15,  3,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int64)),\n",
       " (array(['fotograf', 'fotografia\\xa0', 'fotografie', 'fotogrÃ¡fia',\n",
       "         'photographe', 'photos'], dtype='<U14'),\n",
       "  array([11, 10,  2,  1,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"photography\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['photos', 'imagem_paisagem', 'iphoto', 'imagemap', 'imagej',\n",
       "         'wbmp', '/foto', 'image_caption', 'imagem_', '/timeline/', '/deka',\n",
       "         'mn/', 'movieweb', 'photographer', 'photographo', 'photoimpact',\n",
       "         'imagecount', '//images'], dtype='<U17'),\n",
       "  array([3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['diuca', 'shimao', 'saona', 'ricla', 'pride', 'pri', 'pikul',\n",
       "         'ongkiko', 'niumi', 'ngadi', 'nashik', 'nagatoki', 'moo',\n",
       "         'mokambo', 'manalo', 'komai', 'kanmon', 'ippai', 'ikom', 'goroka',\n",
       "         'gho', 'gebrinio', 'ganale', 'fcr', 'tsuchiura', 'xanax'],\n",
       "        dtype='<U17'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['foton', 'fot', 'fotog', 'fotu', 'fotograf', 'fotografie',\n",
       "         'fotogrÃ¡fa', 'fotoisomerizaÃ§Ã£o', 'fotoluminescÃªncia', 'fotos',\n",
       "         'fÃ³ton'], dtype='<U17'),\n",
       "  array([8, 4, 4, 3, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"photo\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['orthophotography', 'fotography', 'photography', 'photograp',\n",
       "         'photograpgh', 'photography,', 'photograpy', 'âphotograph'],\n",
       "        dtype='<U16'),\n",
       "  array([11,  6,  4,  1,  1,  1,  1,  1], dtype=int64)),\n",
       " (array(['photogram', 'photog', 'photography', 'photography,',\n",
       "         '//photography', 'fotofo', 'fotou', 'kaera', 'nudi',\n",
       "         'photogallery', 'photogaphy', 'photogr', 'photograp',\n",
       "         'photographics', 'photogs', 'âphoto'], dtype='<U16'),\n",
       "  array([6, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['photograp', 'photograpgh', 'photograph,', 'photogram',\n",
       "         'photograpy', 'âphotograph', 'fotography', 'photographics'],\n",
       "        dtype='<U16'),\n",
       "  array([7, 7, 4, 2, 2, 2, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"fotografia\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['#Î²', 'æç¾', 'å··', '\\u3000photo', 'áµ', 'vphoto', 'ufotable', 'treu',\n",
       "         'tjz', 'smartshot', 'ojf', 'oinu', 'nycfoto', 'nsmap', 'newave',\n",
       "         'liabe', 'jxz', 'imge', 'imazamox', 'il_', 'exz', 'eurofoto',\n",
       "         'airmypc', '+no', 'ç²', 'è¡å'], dtype='<U13'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['#screen', 'ucum', 'tanca', 'tambelan', 'streÄen', 'stergo',\n",
       "         'soundgrid', 'semore', 'quinio', 'qto', 'pced', 'liti', 'lapcevic',\n",
       "         'koncu', 'johto', 'fucky', 'fonto', 'fomu', 'erÃª', 'crysos',\n",
       "         'cr&fc', 'ceÄ¼a', 'bristled', 'boric', 'ukcat', 'å­æµ·å¬'], dtype='<U13'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['photok', 'photo,', 'photolab', 'foton', 'fotou', 'phot', 'photo#',\n",
       "         'photodex', 'photoed', 'photoelectric', 'photoes', 'photoetch',\n",
       "         'photogram', 'photographe', 'photogs', 'photovoltage'],\n",
       "        dtype='<U13'),\n",
       "  array([9, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"foto\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['fotografia\\xa0', 'fotografia', 'microfotografia',\n",
       "         'aerofotografia', 'fotogravura', 'macrofotografia',\n",
       "         'fotogrametria'], dtype='<U16'),\n",
       "  array([8, 4, 4, 3, 3, 3, 1], dtype=int64)),\n",
       " (array(['fotografia', 'fotogravura', 'fotografia\\xa0', 'fotogrametria',\n",
       "         'fotojornalismo', 'aerofotografia', 'cronofotografia',\n",
       "         'fotografei', 'fotografem', 'fotogrÃ¡fia', 'kirliangrafia',\n",
       "         'maghroumeh', 'microfotografia', 'videorreportagem'], dtype='<U16'),\n",
       "  array([8, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['fotografia\\xa0', 'fotogravura', 'fotografei', 'fotografem'],\n",
       "        dtype='<U16'),\n",
       "  array([21,  3,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"fotografia\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['#icasa', 'xpdf', 'varredura', 'uÅ¡Äe', 'usÃºario', 'spiess',\n",
       "         'photofolia', 'netmanage', 'lmbassman', 'imagej', 'hydrolase',\n",
       "         'hotol', 'geocities', 'futeboldegoyaz', 'fotosite', 'externo',\n",
       "         'en&nrm', 'com/photos/landshells_freshwater_gastropods/',\n",
       "         'brincadeirinha', 'azulita', 'asa/', 'animepro', '_albirex',\n",
       "         '/print', 'ãã£ã¨', 'ã¿ãã³ã'], dtype='<U44'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['abÃ¼lfaz', 'valmaior', 'setuid', 'retruca', 'pitio', 'pignerol',\n",
       "         'pendjari', 'nescessÃ¡rio', 'melingo', 'maskwak', 'kÃ£', 'katÃº',\n",
       "         'indologia', 'imprenÃ§a', 'gudfred', 'fonto', 'fjÃ¤rde',\n",
       "         'empoleirado', 'edi', 'dosma', 'dennison', 'cecotto', 'benzoato',\n",
       "         'asbs/suzano', 'vetro', 'xdk'], dtype='<U44'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['foton', 'fotogrÃ¡fo', 'fotolitos', 'fotÃ¶', 'microfotografia',\n",
       "         'astrofotÃ³grafo', 'eletrofotografia', 'fotoativa', 'fotodiodo',\n",
       "         'fotoemissÃ£o', 'fotog', 'fotogrÃ¡fa', 'fotogrÃ¡fos', 'fototeca',\n",
       "         'fotovoltaico'], dtype='<U44'),\n",
       "  array([8, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"foto\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['photography', 'orthophotography', 'geophotography'], dtype='<U16'),\n",
       "  array([18,  6,  2], dtype=int64)),\n",
       " (array(['photography', 'photog', 'photogr', 'photograp', 'photography,',\n",
       "         'photography}}', 'goniodes', 'hamri', 'motogp', 'olaba',\n",
       "         'photofit', 'photogen', 'photograper', 'photographer,', 'photomap',\n",
       "         'è¤å´'], dtype='<U16'),\n",
       "  array([6, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['photograp', 'photography', 'photogram', 'photographics',\n",
       "         'photograph,', 'photography,', 'photograpgh', 'photographs'],\n",
       "        dtype='<U16'),\n",
       "  array([8, 5, 4, 3, 2, 2, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"fotografia\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['#Î²', 'cm,', 'åæ', 'â±¦', 'âphoto', 'à¶à·à¶«', 'Î±tc', 'zbg', 'yarara',\n",
       "         'xyg', 'svgimage', 'sc,', 'ppix', 'photograph', 'photobank', 'pgv',\n",
       "         'mwha', 'lmap', 'kilometr', 'ixy', 'dlsv', 'closeup', 'ç¿', 'ï¼ã'],\n",
       "        dtype='<U13'),\n",
       "  array([2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1], dtype=int64)),\n",
       " (array(['>ho', 'ææ', 'à¸', 'Â·na', 'verranno', 'tiuj', 'smarte', 'qyzyl',\n",
       "         'plodn', 'nlib', 'nemah', 'meali', 'lykos', 'lagou', 'hornish',\n",
       "         'honer', 'gieri', 'ganet', 'fonto', 'fluga', 'citran', 'caval',\n",
       "         'astronom', '`n`', 'çç¥å­', 'ì¬ì´'], dtype='<U13'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['photok', 'photoed', 'photoink', 'photo,', 'photos', 'photolab',\n",
       "         'photojournal', 'photograp', 'photogram', 'photoglo', 'photofile',\n",
       "         'photof', 'photoetch', 'photoelectric', 'photocd', 'photoby',\n",
       "         'photostat', 'phototube'], dtype='<U13'),\n",
       "  array([7, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"foto\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['astrofotografia', 'fotografica', 'macrofotografia'], dtype='<U15'),\n",
       "  array([20,  5,  1], dtype=int64)),\n",
       " (array(['fotografia', 'fotogiglio', 'astrofotografia', 'fotografica',\n",
       "         'photobeamer', 'eremomela', 'fotografandolo', 'fotografiaÂ»',\n",
       "         'guanahani', 'jamize', 'lucorano', 'sportscar'], dtype='<U15'),\n",
       "  array([7, 4, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1], dtype=int64)),\n",
       " (array(['fotografic', 'fotografica', 'fotogr', 'fotografe', 'fotografia',\n",
       "         'fotografie'], dtype='<U15'),\n",
       "  array([20,  2,  1,  1,  1,  1], dtype=int64))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"fotografia\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 26 26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['atral', 'Îµr', 'Âµv/Â°c', 'us_open_', 'spjÃ³t', 'rimappatura',\n",
       "         'riflettografia', 'retinale', 'pmvc', 'plb', 'photodraw', 'pgv',\n",
       "         'o/rame', 'minisito', 'microindentazione', 'mhf', 'mangabeira',\n",
       "         'jq', 'immagine', 'fototubo', 'fotorifrattivo', 'foto_veicolo',\n",
       "         'foto', 'diametro_alla_base', 'â ', 'ã­ã¥ã¼ãã£ã¼ããã¼'], dtype='<U18'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['acmsetup', 'tigerbeat', 'rustom', 'probotector', 'kakkab',\n",
       "         'glÃ¤ubet', 'gerÃ¶', 'galvanoplastica', 'furst', 'foyt', 'foot/',\n",
       "         'fonto', 'diffcile', 'cÃ³rso', 'cÃ ndito', 'cunfida', 'caÃ¹to',\n",
       "         'bulÃ¨ta', 'bravissima', 'bombolone', 'beruatto', 'astronomico',\n",
       "         'akuaduulza', 'adzope', 'wyton', 'Ê¿forte'], dtype='<U18'),\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1], dtype=int64)),\n",
       " (array(['fotoit', 'fotograf', 'photobeamer', 'fotoluminescenza', 'photodo',\n",
       "         'fotorivelatore', 'foto,', 'photobiol', 'fototubo', 'fotosensore',\n",
       "         'foton', 'fotorama', 'fotoliasi', 'fotografie', 'fotografic',\n",
       "         'fotogr', 'fotoreportage', 'photovoltaic'], dtype='<U18'),\n",
       "  array([4, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"foto\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: take random words from ita_new and watch the closest in eng_new and see if the pattern is the same with fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eng_aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m ita_word \u001b[38;5;241m=\u001b[39m ita_new\u001b[38;5;241m.\u001b[39mindex_to_key[i]\n\u001b[0;32m      9\u001b[0m eng_word_ew \u001b[38;5;241m=\u001b[39m eng_new\u001b[38;5;241m.\u001b[39mindex_to_key[find_closest_vector(ita_new[ita_word], eng_new\u001b[38;5;241m.\u001b[39mvectors)]\n\u001b[1;32m---> 10\u001b[0m eng_word_aw \u001b[38;5;241m=\u001b[39m \u001b[43meng_aligned\u001b[49m\u001b[38;5;241m.\u001b[39mindex_to_key[find_closest_vector(ita_aligned[ita_word], eng_aligned\u001b[38;5;241m.\u001b[39mvectors)]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ita_new\u001b[38;5;241m.\u001b[39mindex_to_key[i] \u001b[38;5;241m!=\u001b[39m ita_aligned\u001b[38;5;241m.\u001b[39mindex_to_key[i]:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROBLEM: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eng_aligned' is not defined"
     ]
    }
   ],
   "source": [
    "# generate 2000 random indexes between 0 and ita_new.index_to_key length \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "idx = np.random.randint(0, 4000, 2000)\n",
    "\n",
    "for i in idx:\n",
    "    ita_word = ita_new.index_to_key[i]\n",
    "    eng_word_ew = eng_new.index_to_key[find_closest_vector(ita_new[ita_word], eng_new.vectors)]\n",
    "    eng_word_aw = eng_aligned.index_to_key[find_closest_vector(ita_aligned[ita_word], eng_aligned.vectors)]\n",
    "\n",
    "    if ita_new.index_to_key[i] != ita_aligned.index_to_key[i]:\n",
    "        print(\"PROBLEM: \", i)\n",
    "    \n",
    "    if eng_word_ew != eng_word_aw:\n",
    "        print(ita_word, eng_word_ew, eng_word_aw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_words(word):\n",
    "    words = []\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = c + word\n",
    "        words.append(new_word)\n",
    "\n",
    "    mid = len(word) // 2\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word[:mid] + c + word[mid:]\n",
    "        words.append(new_word)\n",
    "\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word + c\n",
    "        words.append(new_word)\n",
    "    return words\n",
    "\n",
    "len(generate_words(\"casa\")) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pickle\n",
    "\n",
    "def find_matrix(lang, step=1000):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "    dict = {}\n",
    "\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "    \n",
    "    if src.index_to_key != dst.index_to_key:\n",
    "        print(\"src and dst vocabularies differ. \")\n",
    "        print(\"src\", len(src))\n",
    "        print(\"dst\", len(dst))\n",
    "        print(\"in src, not in dst\", set(src.index_to_key) - set(dst.index_to_key))\n",
    "        print(\"in dst, not in src\", set(dst.index_to_key) - set(src.index_to_key))\n",
    "    \n",
    "    dict[\"missing_elements\"] = [set(src.index_to_key) - set(dst.index_to_key), set(dst.index_to_key) - set(src.index_to_key)] # missing words in common vocabulary\n",
    "\n",
    "    vocab = sorted(list(set(src.index_to_key) & set(dst.index_to_key)))\n",
    "        \n",
    "    Y = dst[vocab]\n",
    "    X = src[vocab]\n",
    "\n",
    "    W_ = np.linalg.pinv(X) @ Y\n",
    "\n",
    "    prod = (X @ W_)\n",
    "    prod = prod / np.linalg.norm(prod, axis=1).reshape(-1,1)\n",
    "\n",
    "    dict[\"MSE\"] = np.square(np.subtract(prod, Y)).sum(axis=1).mean() # mean squared error\n",
    "\n",
    "    error_couples = []\n",
    "    right_values = np.array([])\n",
    "\n",
    "    for i in range(0, len(prod), step):\n",
    "            M = (prod[i:i+step] @ Y.T)\n",
    "            v = M.argmax(axis=1)\n",
    "\n",
    "            # sum of the diagonal\n",
    "            right_values = np.concatenate((right_values, np.diagonal(M[:,v])))\n",
    "            for j in range(len(v)):\n",
    "                if v[j] != i+j: # check that the most vector is the word itself\n",
    "                    print(\"words do not match\", i+j, v[j], M[j,v[j]])\n",
    "                    print(\"instead the right word should be \", M[j,j])\n",
    "                    error_couples.append((i+j, v[j], M[j,v[j]], M[j,j]))\n",
    "\n",
    "            print(i, \"/\", len(prod), \"done\") if i % 50_000 == 0 else None\n",
    "    \n",
    "    dict[\"accuracy\"] = (right_values.mean(), right_values.std()) # values of the diagonal of the matrix\n",
    "    dict[\"n_errors\"] = len(error_couples) # number of errors\n",
    "\n",
    "    src.vectors = src.vectors @ W_\n",
    "    src.vectors_ngrams = src.vectors_ngrams @ W_\n",
    "    src.vectors = src.vectors / np.linalg.norm(src.vectors, axis=1).reshape(-1,1)\n",
    "    src.vectors_ngrams = src.vectors_ngrams / np.linalg.norm(src.vectors_ngrams, axis=1).reshape(-1,1)\n",
    "\n",
    "    return src, X, Y, W_, right_values, error_couples, dict\n",
    "\n",
    "            \n",
    "lang = \"af\"         \n",
    "src, X, Y, W_, right_values, error_couples, dict = find_matrix(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "\n",
    "def create_bin(lang):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    \n",
    "    path = \"W/\"\n",
    "    file = f\"{lang}.pkl\"\n",
    "    with open(os.path.join(path, file), \"rb\") as f:\n",
    "        W_ = pickle.load(f)\n",
    "\n",
    "    src.vectors = src.vectors @ W_\n",
    "    src.vectors_ngrams = src.vectors_ngrams @ W_\n",
    "    src.vectors = src.vectors / np.linalg.norm(src.vectors, axis=1).reshape(-1,1)\n",
    "    src.vectors_ngrams = src.vectors_ngrams / np.linalg.norm(src.vectors_ngrams, axis=1).reshape(-1,1)\n",
    "\n",
    "    return W_, src \n",
    "\n",
    "W1, src1 = create_bin(\"af\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src2 = KeyedVectors.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin\")\n",
    "vectors_ngrams = np.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin.vectors_ngrams.npy\", allow_pickle=True)\n",
    "vectors_vocab = np.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin.vectors_vocab.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(src.vectors == src1.vectors).all(), (src.vectors_ngrams == vectors_ngrams).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonk = KeyedVectors.load(\"test\")\n",
    "bonk.vectors == src.vectors, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain.vectors = src.vectors\n",
    "plain.vectors_ngrams = src.vectors_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, X, Y, W_, right_values, error_couples, dict = find_matrix(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save src with pickle \n",
    "\n",
    "import pickle\n",
    "\n",
    "path = \"W/\"\n",
    "file = f\"{lang}.pkl\"\n",
    "\n",
    "with open(f\"test2\", \"wb\") as f:\n",
    "                pickle.dump((src), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load src with pickle\n",
    "with open(f\"test2\", \"rb\") as f:\n",
    "    bonk = pickle.load(f)\n",
    "\n",
    "(bonk.vectors == src.vectors).all(), (bonk.vectors_ngrams == src.vectors_ngrams).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"af\"\n",
    "with open(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    bonk2 = pickle.load(f)\n",
    "\n",
    "(bonk2.vectors == src.vectors).all(), (bonk2.vectors_ngrams == src.vectors_ngrams).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = KeyedVectors.load(\"test\")\n",
    "vectors_ngrams = np.load(\"test.vectors_ngrams.npy\", allow_pickle=True)\n",
    "vectors_vocab = np.load(f\"test.vectors_vocab.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_ngrams.shape, vectors_vocab.shape, src.vectors_ngrams.shape, src.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vectors_vocab[0]\n",
    "\n",
    "for row in src.vectors:\n",
    "    if (row == v).all():\n",
    "        print(\"found\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors_ngrams == vectors_ngrams, src.vectors == vectors_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.vectors_ngrams == vectors_ngrams, test_model.vectors == src.vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
