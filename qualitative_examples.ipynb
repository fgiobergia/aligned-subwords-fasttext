{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_vector(v, M, n = 1):\n",
    "    indices = np.flip(np.argsort(np.dot(M, v)))[:n]\n",
    "    return indices[0] if n == 1 else indices\n",
    "\n",
    "def print_examples(starting_language, target_language, word): \n",
    "    idx = find_closest_vector(starting_language[word], target_language.vectors)\n",
    "    result = target_language.index_to_key[idx]\n",
    "    #print(starting_language.has_index_for(word), result, idx)\n",
    "    return result\n",
    "\n",
    "# make a function that taken a word, it generates all the words that are the same but with every letter of the alphabet added at the beginning, then in the middle, then at the end \n",
    "\n",
    "def generate_words(word):\n",
    "    words = []\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = c + word\n",
    "        words.append(new_word)\n",
    "\n",
    "    mid = len(word) // 2\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word[:mid] + c + word[mid:]\n",
    "        words.append(new_word)\n",
    "\n",
    "    for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        new_word = word + c\n",
    "        words.append(new_word)\n",
    "    return words\n",
    "\n",
    "\n",
    "# make a function that given a list of words, return for each word the closest word in the target language \n",
    "\n",
    "def find_closest_words(starting_language, target_language, words):\n",
    "    results = []\n",
    "    for word in words:\n",
    "        results.append(print_examples(starting_language, target_language, word))\n",
    "    return results\n",
    "\n",
    "def split_vector(v, n):\n",
    "    return np.array_split(v, n)\n",
    "\n",
    "# split the vector of results in three subvectors of the same length \n",
    "def noise_experiment(starting_language, target_language, word):\n",
    "    res = find_closest_words(starting_language, target_language, generate_words(word))\n",
    "    temp = split_vector(res, 3)\n",
    "\n",
    "    # return the number of each word for the subvectors ordered by their frequency\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(temp)):\n",
    "        values, counts = np.unique(temp[i], return_counts=True)\n",
    "        ordered_indexes = np.argsort(-counts)\n",
    "        results.append((values[ordered_indexes], counts[ordered_indexes]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heron_path = \"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/\"\n",
    "# print(\"loading italian vectors\")\n",
    "# ita_aligned = KeyedVectors.load_word2vec_format(f\"wiki.it.align.vec\")\n",
    "# print(\"loading english vectors\")\n",
    "# eng_aligned = KeyedVectors.load_word2vec_format(f\"wiki.en.align.vec\")\n",
    "#ita_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.it.bin\") \n",
    "#eng_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.en.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look if the normal words are aligned with the same words of fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading italian vectors\n",
      "loading english vectors\n",
      "loading portuguese vectors\n"
     ]
    }
   ],
   "source": [
    "lang = \"it\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading italian vectors\")\n",
    "with open(f\"{heron_path}wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    ita_new = pickle.load(f)\n",
    "\n",
    "lang = \"en\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading english vectors\")\n",
    "with open(f\"{heron_path}wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    eng_new = pickle.load(f)\n",
    "\n",
    "lang = \"pt\"\n",
    "heron_path = f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/\"\n",
    "\n",
    "print(\"loading portuguese vectors\")\n",
    "with open(f\"{heron_path}wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    pt_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32592416, 0.3984447 ],\n",
       "       [0.84792559, 1.24908104],\n",
       "       [0.54792281, 0.6696265 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a 2x2 random matrix \n",
    "\n",
    "a = np.random.rand(2, 2)\n",
    "b = np.random.rand(3, 2)\n",
    "\n",
    "b@a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], ita_aligned.vectors)\n",
    "\n",
    "ita_aligned.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vector, find in a matrix the closest vector to it\n",
    "# VALUTA DI USARE get_vector() per ottenere il vettore di una parola\n",
    "\n",
    "idx = find_closest_vector(ita_new[\"ciao\"], eng_new.vectors)\n",
    "idx2 = find_closest_vector(ita_new[\"ciao\"], eng_aligned.vectors)\n",
    "eng_new.index_to_key[idx], idx, eng_aligned.index_to_key[idx2], idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"gatto\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"papero\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_aligned[\"ciao\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"casa\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx) \n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"gatto\"], eng_aligned.vectors)   \n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"papero\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words with typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"pomodoriniq\"\n",
    "\n",
    "print_examples(ita_new, eng_new, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"alberelo\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], ita_new.vectors)\n",
    "key = ita_new.index_to_key[idx]\n",
    "print(key, idx)\n",
    "idx = find_closest_vector(ita_new[key], eng_new.vectors)\n",
    "print(ita_new.has_index_for(word), eng_new.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"albero\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], ita_new.vectors)\n",
    "key = ita_new.index_to_key[idx]\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors, 10)\n",
    "print(ita_new.has_index_for(word))\n",
    "print()\n",
    "for i in idx: \n",
    "    print(eng_new.index_to_key[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elephant -> Elefante -> Elefant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"elephant\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"elephant\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"elefante\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"elefante\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"elefante\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"elefante\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple -> Mela -> Maçã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"apple\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"apple\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"mela\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"mela\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"maçã\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"maçã\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Butterfly -> Farfalla -> Borboleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"butterfly\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"butterfly\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"farfalla\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"farfalla\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"borboleta\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"borboleta\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cat -> Gatto -> Gato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"cat\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"cat\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"gatto\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"gatto\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"gato\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"gato\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"photography\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"photo\")\n",
    "eng_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"photography\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pt = noise_experiment(eng_new, pt_new, \"photo\")\n",
    "eng_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"fotografia\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"foto\")\n",
    "ita_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"fotografia\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_pt = noise_experiment(ita_new, pt_new, \"foto\")\n",
    "ita_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"fotografia\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_eng = noise_experiment(pt_new, eng_new, \"foto\")\n",
    "pt_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"fotografia\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ita = noise_experiment(pt_new, ita_new, \"foto\")\n",
    "pt_ita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ita_eng = noise_experiment(ita_new, eng_new, \"pecora\")\n",
    "ita_eng, print_examples(ita_new, eng_new, \"pecora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_ita = noise_experiment(eng_new, ita_new, \"sheep\")\n",
    "eng_ita, print_examples(eng_new, ita_new, \"sheep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_language(model1, model2, word, fraction = True):\n",
    "    results = []\n",
    "    closest_word = print_examples(model1, model2, word)\n",
    "    res = noise_experiment(model1, model2, word)\n",
    "    found = [0, 0, 0]\n",
    "    for i in range(3):\n",
    "        if closest_word in res[i][0]:\n",
    "            found[i] = res[i][1][np.where(res[i][0] == closest_word)[0][0]]\n",
    "            if fraction:\n",
    "                found[i] /= sum(res[i][1])\n",
    "    results.append((word, closest_word, found))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_language(eng_new, ita_new, \"elephant\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_language(ita_new, eng_new, \"elefante\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_per_lang = []\n",
    "\n",
    "english_words = [\n",
    "    'elephant', 'apple', 'cat', 'butterfly', 'strawberry', 'university', 'magnificent', \n",
    "    'adventure', 'imagination', 'celebration', 'compassionate', 'extraordinary', 'friendship',\n",
    "    'relationship', 'understanding', 'delicious', 'adventure', 'enthusiasm',\n",
    "    'photography', 'restaurant', 'important', 'television', 'dictionary',\n",
    "    'hospitality', 'independent', 'government', 'scientific', 'architecture',\n",
    "    'responsibility', 'improvement', 'communication', 'opportunity', 'transportation',\n",
    "    'environment', 'motivation', 'conversation', 'performance', 'appreciation',\n",
    "    'cooperation', 'knowledge', 'adventure', 'sophisticated', 'imagination',\n",
    "    'composition', 'presentation', 'international', 'determination', 'intelligence',\n",
    "    'philosophy', 'psychology', 'unforgettable', 'recommendation', 'collaboration',\n",
    "    'contribution', 'productivity', 'concentration', 'development', 'achievement',\n",
    "    'fundamental', 'achievement', 'satisfaction', 'appreciation', 'celebration',\n",
    "    'conversation', 'dedication', 'determination', 'excellence', 'fascination',\n",
    "    'gratitude', 'hospitality', 'improvement', 'independence'\n",
    "]\n",
    "\n",
    "print (english_words)\n",
    "\n",
    "for word in english_words:\n",
    "    words_per_lang.append({\n",
    "        'english': word,\n",
    "        'italian': print_examples(eng_new, ita_new, word),\n",
    "        'portuguese': print_examples(eng_new, pt_new, word)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "eng_new.language = \"english\"\n",
    "ita_new.language = \"italian\"\n",
    "pt_new.language = \"portuguese\"\n",
    "\n",
    "models = [eng_new, ita_new, pt_new]\n",
    "\n",
    "for word_per_lang in words_per_lang:\n",
    "    print(word_per_lang)\n",
    "    for model1 in models:\n",
    "        for model2 in models:\n",
    "            if model1 != model2:\n",
    "                print(f\"evaluating {model1.language} to {model2.language}\")\n",
    "                word = word_per_lang[model1.language]\n",
    "                result = evaluate_language(model1, model2, word)\n",
    "                print(result)\n",
    "                # Use a tuple of languages and word as the key\n",
    "                results[(model1.language, model2.language, word)] = result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
