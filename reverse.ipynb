{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matrix(lang, step=5000):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "    \n",
    "    if src.index_to_key != dst.index_to_key:\n",
    "        print(\"src and dst vocabularies differ. \")\n",
    "        print(\"src\", len(src))\n",
    "        print(\"dst\", len(dst))\n",
    "        print(\"in src, not in dst\", set(src.index_to_key) - set(dst.index_to_key))\n",
    "        print(\"in dst, not in src\", set(dst.index_to_key) - set(src.index_to_key))\n",
    "    \n",
    "    vocab = list(set(src.index_to_key) & set(dst.index_to_key))\n",
    "        \n",
    "    Y = dst[vocab]\n",
    "    X = src[vocab]\n",
    "\n",
    "    W_ = np.linalg.pinv(X) @ Y\n",
    "\n",
    "    prod = (X @ W_)\n",
    "    prod = prod / np.linalg.norm(prod, axis=1).reshape(-1,1)\n",
    "\n",
    "    error_couples = []\n",
    "    right_values = []\n",
    "\n",
    "    for i in range(0, len(prod), step):\n",
    "            M = (prod[i:i+step] @ Y.T)\n",
    "            v = M.argmax(axis=1)\n",
    "\n",
    "            # sum of the diagonal\n",
    "            right_values.append(np.diagonal(M[:,v]))\n",
    "            for j in range(len(v)):\n",
    "                if v[j] != i+j: # check that the most vector is the word itself\n",
    "                    print(\"words do not match\", i+j, v[j], M[j,v[j]])\n",
    "                    print(\"instead the right word should be \", M[j,j])\n",
    "                    error_couples.append((i+j, v[j], M[j,v[j]], M[j,j]))\n",
    "\n",
    "                if M[j,v[j]] < .98:\n",
    "                    print(\"small similarity\" , i+j, v[j], M[j,v[j]])\n",
    "    \n",
    "    return src, dst, X, Y, W_, right_values.mean(), right_values.std(), error_couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst, X, Y, W_, mean, std, error_couples = find_matrix(\"it\")\n",
    "\n",
    "# save the values \n",
    "import pickle\n",
    "with open(\"it.pkl\", \"wb\") as f:\n",
    "    pickle.dump((src, dst, X, Y, W_, mean, std, error_couples), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, dst, X, Y, W_, mean, std, error_couples = find_matrix(\"it\")\n",
    "\n",
    "with open(\"it.pkl\", \"wb\") as f:\n",
    "    pickle.dump((src, dst, X, Y, W_, mean, std, error_couples), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"res/it.pkl\", \"rb\") as f:\n",
    "    X, Y, W_, mean, std, error_couples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape, W_.shape, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"it\"\n",
    "\n",
    "try:\n",
    "    src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "    print(\"Loaded fastText vectors\")\n",
    "except:\n",
    "    print(\"Going to 'vec'\")\n",
    "    src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src.vectors_ngrams)\n",
    "\n",
    "src.vectors.shape, src.vectors_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.index_to_key[1000], src.buckets_word[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [] \n",
    "for i, n in enumerate(src.buckets_word): \n",
    "    # if in the list there is at least one index in src.buckets_word[1000], take the index \n",
    "    if len(set(n) & set(src.buckets_word[1000])) == 0 and i > 1000:\n",
    "        list.append(i)\n",
    "    if len(list) > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list:\n",
    "    print(src.index_to_key[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 300)\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test = deepcopy(src.vectors_ngrams)\n",
    "print(test.shape)\n",
    "\n",
    "# change the vectors of the ngrams\n",
    "for i in range(10):\n",
    "    src.vectors_ngrams[i] = np.random.rand(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors_ngrams = np.random.rand(src.vectors_ngrams.shape[0], 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0] == src.vectors_ngrams[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 19/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANG hi\n",
      "Loaded fastText vectors\n"
     ]
    }
   ],
   "source": [
    "lang = \"hi\"\n",
    "\n",
    "print(\"LANG\", lang)\n",
    "# not aligned\n",
    "try:\n",
    "    src1 = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "    print(\"Loaded fastText vectors\")\n",
    "except:\n",
    "    print(\"Going to 'vec'\")\n",
    "    src1 = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "dst1 = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "\n",
    "if src1.index_to_key != dst1.index_to_key:\n",
    "    print(\"src and dst1 vocabularies differ. \")\n",
    "    print(\"src\", len(src1))\n",
    "    print(\"dst1\", len(dst1))\n",
    "    print(\"in src, not in dst1\", set(src1.index_to_key) - set(dst1.index_to_key))\n",
    "    print(\"in dst1, not in src1\", set(dst1.index_to_key) - set(src1.index_to_key))\n",
    "\n",
    "vocab1 = sorted(list(set(src1.index_to_key) & set(dst1.index_to_key)))\n",
    "    \n",
    "Y1 = dst1[vocab1]\n",
    "X1 = src1[vocab1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(f\"res/{lang}.pkl\", \"rb\") as f:\n",
    "    src, dst, X, Y, W_, mean, std, error_couples, vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "(dst.vectors == dst1.vectors).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 = list(set(src1.index_to_key) & set(dst1.index_to_key))\n",
    "vocab = list(set(src.index_to_key) & set(dst.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab1 == vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(src[vocab] == X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X == X1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X[0]\n",
    "\n",
    "(X == X1[0]).all(axis=1).nonzero(), (X == X1[1]).all(axis=1).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = src[vocab]\n",
    "X3 = src1[vocab]\n",
    "(X2 == X1).all(), (X3 == X1).all(), (X2 == X3).all(), (X2 == X).all(), (X3 == X).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][2], X1[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(src1.index_to_key) & set(dst1.index_to_key))\n",
    "vocab1 = list(set(src.index_to_key) & set(dst.index_to_key))\n",
    "\n",
    "vocab[0], vocab1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = (X @ W_)\n",
    "prod_norm = prod / np.linalg.norm(prod, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = []\n",
    "v2 = []\n",
    "for elem in error_couples:\n",
    "    v1.append(elem[0])\n",
    "    v2.append(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in v1: \n",
    "    print(i, np.linalg.norm(prod[i]), np.linalg.norm(prod_norm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in v2: \n",
    "    print(i, np.linalg.norm(prod[i]), np.linalg.norm(prod_norm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(v1, v2): \n",
    "    print(dst.index_to_key[i], dst.index_to_key[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pickle\n",
    "\n",
    "def find_matrix(lang, step=1000):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "    dict = {}\n",
    "\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "    \n",
    "    if src.index_to_key != dst.index_to_key:\n",
    "        print(\"src and dst vocabularies differ. \")\n",
    "        print(\"src\", len(src))\n",
    "        print(\"dst\", len(dst))\n",
    "        print(\"in src, not in dst\", set(src.index_to_key) - set(dst.index_to_key))\n",
    "        print(\"in dst, not in src\", set(dst.index_to_key) - set(src.index_to_key))\n",
    "    \n",
    "    dict[\"missing_elements\"] = [set(src.index_to_key) - set(dst.index_to_key), set(dst.index_to_key) - set(src.index_to_key)]\n",
    "\n",
    "    vocab = sorted(list(set(src.index_to_key) & set(dst.index_to_key)))\n",
    "        \n",
    "    Y = dst[vocab]\n",
    "    X = src[vocab]\n",
    "\n",
    "    W_ = np.linalg.pinv(X) @ Y\n",
    "\n",
    "    prod = (X @ W_)\n",
    "    prod = prod / np.linalg.norm(prod, axis=1).reshape(-1,1)\n",
    "\n",
    "    dict[\"MSE\"] = np.square(np.subtract(prod, Y)).sum(axis=1).mean()\n",
    "\n",
    "    error_couples = []\n",
    "    right_values = np.array([])\n",
    "\n",
    "    for i in range(0, len(prod), step):\n",
    "            #einstein summation for matrix multiplication (einsum) \n",
    "            M = (prod[i:i+step] @ Y.T)\n",
    "            v = M.argmax(axis=1)\n",
    "\n",
    "            # sum of the diagonal\n",
    "            right_values = np.concatenate((right_values, np.diagonal(M[:,v])))\n",
    "            for j in range(len(v)):\n",
    "                if v[j] != i+j: # check that the most vector is the word itself\n",
    "                    print(\"words do not match\", i+j, v[j], M[j,v[j]])\n",
    "                    print(\"instead the right word should be \", M[j,j])\n",
    "                    error_couples.append((i+j, v[j], M[j,v[j]], M[j,j]))\n",
    "\n",
    "                #if M[j,v[j]] < .98:\n",
    "                #    print(\"small similarity\" , i+j, v[j], M[j,v[j]])\n",
    "            \n",
    "            print(i, \"/\", len(prod), \"done\") if i % 50_000 == 0 else None\n",
    "    \n",
    "    dict[\"accuracy\"] = (right_values.mean(), right_values.std()) \n",
    "    dict[\"n_errors\"] = len(error_couples)\n",
    "\n",
    "    return X, Y, W_, right_values, error_couples, dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANG hi\n",
      "Loaded fastText vectors\n",
      "0 / 158016 done\n",
      "words do not match 1049 1048 0.9980334\n",
      "instead the right word should be  0.16828963\n",
      "words do not match 14857 14858 0.99202466\n",
      "instead the right word should be  0.30169815\n",
      "words do not match 19223 19224 0.9911644\n",
      "instead the right word should be  -0.06508929\n",
      "words do not match 35661 35663 0.99709684\n",
      "instead the right word should be  0.23811021\n",
      "words do not match 35662 35664 0.9972795\n",
      "instead the right word should be  0.049840372\n",
      "words do not match 35663 35667 0.9973093\n",
      "instead the right word should be  0.10174778\n",
      "words do not match 35664 35669 0.9974661\n",
      "instead the right word should be  0.13475055\n",
      "words do not match 35665 35672 0.9975953\n",
      "instead the right word should be  -0.026788184\n",
      "words do not match 35666 35676 0.99767566\n",
      "instead the right word should be  0.049099855\n",
      "words do not match 35667 35677 0.99770594\n",
      "instead the right word should be  0.1546953\n",
      "words do not match 35668 35677 0.997769\n",
      "instead the right word should be  0.16078879\n",
      "words do not match 35669 35679 0.9978312\n",
      "instead the right word should be  0.19909544\n",
      "words do not match 35670 35679 0.9978765\n",
      "instead the right word should be  0.069502\n",
      "words do not match 35671 35679 0.9977987\n",
      "instead the right word should be  0.23350447\n",
      "words do not match 35672 35679 0.99770534\n",
      "instead the right word should be  0.2787489\n",
      "words do not match 35673 35679 0.9976065\n",
      "instead the right word should be  0.37847176\n",
      "words do not match 35674 35679 0.99746794\n",
      "instead the right word should be  0.49395895\n",
      "words do not match 35675 35679 0.9971679\n",
      "instead the right word should be  -0.07163867\n",
      "words do not match 35676 35679 0.99685293\n",
      "instead the right word should be  0.033723243\n",
      "words do not match 35677 35679 0.99531794\n",
      "instead the right word should be  0.10428207\n",
      "words do not match 35678 35679 0.99499637\n",
      "instead the right word should be  0.22566567\n",
      "50000 / 158016 done\n",
      "100000 / 158016 done\n",
      "150000 / 158016 done\n"
     ]
    }
   ],
   "source": [
    "X, Y, W_, right_values, error_couples, dict = find_matrix(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.vectors = src.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999969"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(dst.vectors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.fasttext.FastTextKeyedVectors"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prod*Y).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors = src.vectors @ W_\n",
    "src.vectors_ngrams = src.vectors_ngrams @ W_\n",
    "\n",
    "src.vectors = src.vectors / np.linalg.norm(src.vectors, axis=1).reshape(-1,1)\n",
    "src.vectors_ngrams = src.vectors_ngrams / np.linalg.norm(src.vectors_ngrams, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99999994, 1.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# norm of the vectors\n",
    "\n",
    "np.linalg.norm(src.vectors[2]), np.linalg.norm(src.vectors_ngrams[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bin file \n",
    "#src.save(f\"test.bin\")\n",
    "src.save_word2vec_format(f\"test2.bin\")\n",
    "#src.save_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/wiki.{lang}.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load bin file\n",
    "import gensim\n",
    "\n",
    "#src2 = gensim.models.fasttext.FastTextKeyedVectors.load(f\"test/test.bin\", mmap='r')\n",
    "\n",
    "# load vec file\n",
    "src3 = KeyedVectors.load_word2vec_format(f\"test2.bin\")\n",
    "\n",
    "(src3.vectors[0] == src.vectors[0]).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
