{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_vector(v, M, n = 1):\n",
    "    return np.flip(np.argsort(np.dot(M, v)))[:n] if n != 1 else np.argmax(np.dot(M,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data1/malto/csavelli/aligned_subwords_fasttext/\"\n",
    "\n",
    "ita_aligned = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.it.align.vec\")\n",
    "eng_aligned = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.en.align.vec\")\n",
    "#ita_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.it.bin\") \n",
    "#eng_wiki = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.en.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look if the normal words are aligned with the same words of fastText. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"it\"\n",
    "\n",
    "with open(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    ita_new = pickle.load(f)\n",
    "\n",
    "lang = \"en\"\n",
    "\n",
    "with open(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    eng_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('casa', 228)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], ita_aligned.vectors)\n",
    "\n",
    "ita_aligned.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a vector, find in a matrix the closest vector to it\n",
    "# VALUTA DI USARE get_vector() per ottenere il vettore di una parola\n",
    "\n",
    "idx = find_closest_vector(ita_new[\"ciao\"], eng_new.vectors)\n",
    "idx2 = find_closest_vector(ita_new[\"ciao\"], eng_aligned.vectors)\n",
    "eng_new.index_to_key[idx], idx, eng_aligned.index_to_key[idx2], idx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"casa\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"gatto\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_new[\"papero\"], eng_new.vectors)\n",
    "eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_aligned[\"ciao\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"casa\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx) \n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"gatto\"], eng_aligned.vectors)   \n",
    "print(eng_aligned.index_to_key[idx], idx)\n",
    "\n",
    "idx = find_closest_vector(ita_aligned[\"papero\"], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"balenottero\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors)\n",
    "ita_new.has_index_for(word), eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"pomodoriniq\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors)\n",
    "ita_new.has_index_for(word), eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"alberelo\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], ita_new.vectors)\n",
    "key = ita_new.index_to_key[idx]\n",
    "print(key, idx)\n",
    "print()\n",
    "idx = find_closest_vector(ita_new[key], eng_new.vectors)\n",
    "print(eng_new.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"orchetti\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors, 10)\n",
    "for i in idx: \n",
    "    print(ita_new.has_index_for(word), eng_new.index_to_key[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_closest_vector(ita_aligned[word], eng_aligned.vectors)\n",
    "print(eng_aligned.index_to_key[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"topolino\"\n",
    "\n",
    "idx = find_closest_vector(ita_new[word], eng_new.vectors)\n",
    "ita_new.has_index_for(word), eng_new.index_to_key[idx], idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5: take random words from ita_new and watch the closest in eng_new and see if the pattern is the same with fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 2000 random indexes between 0 and ita_new.index_to_key length \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "idx = np.random.randint(0, 4000, 2000)\n",
    "\n",
    "for i in idx:\n",
    "    ita_word = ita_new.index_to_key[i]\n",
    "    eng_word_ew = eng_new.index_to_key[find_closest_vector(ita_new[ita_word], eng_new.vectors)]\n",
    "    eng_word_aw = eng_aligned.index_to_key[find_closest_vector(ita_aligned[ita_word], eng_aligned.vectors)]\n",
    "\n",
    "    if ita_new.index_to_key[i] != ita_aligned.index_to_key[i]:\n",
    "        print(\"PROBLEM: \", i)\n",
    "    \n",
    "    if eng_word_ew != eng_word_aw:\n",
    "        print(ita_word, eng_word_ew, eng_word_aw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pickle\n",
    "\n",
    "def find_matrix(lang, step=1000):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "    dict = {}\n",
    "\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    dst = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/aligned/wiki.{lang}.align.vec\") # aligned\n",
    "    \n",
    "    if src.index_to_key != dst.index_to_key:\n",
    "        print(\"src and dst vocabularies differ. \")\n",
    "        print(\"src\", len(src))\n",
    "        print(\"dst\", len(dst))\n",
    "        print(\"in src, not in dst\", set(src.index_to_key) - set(dst.index_to_key))\n",
    "        print(\"in dst, not in src\", set(dst.index_to_key) - set(src.index_to_key))\n",
    "    \n",
    "    dict[\"missing_elements\"] = [set(src.index_to_key) - set(dst.index_to_key), set(dst.index_to_key) - set(src.index_to_key)] # missing words in common vocabulary\n",
    "\n",
    "    vocab = sorted(list(set(src.index_to_key) & set(dst.index_to_key)))\n",
    "        \n",
    "    Y = dst[vocab]\n",
    "    X = src[vocab]\n",
    "\n",
    "    W_ = np.linalg.pinv(X) @ Y\n",
    "\n",
    "    prod = (X @ W_)\n",
    "    prod = prod / np.linalg.norm(prod, axis=1).reshape(-1,1)\n",
    "\n",
    "    dict[\"MSE\"] = np.square(np.subtract(prod, Y)).sum(axis=1).mean() # mean squared error\n",
    "\n",
    "    error_couples = []\n",
    "    right_values = np.array([])\n",
    "\n",
    "    for i in range(0, len(prod), step):\n",
    "            M = (prod[i:i+step] @ Y.T)\n",
    "            v = M.argmax(axis=1)\n",
    "\n",
    "            # sum of the diagonal\n",
    "            right_values = np.concatenate((right_values, np.diagonal(M[:,v])))\n",
    "            for j in range(len(v)):\n",
    "                if v[j] != i+j: # check that the most vector is the word itself\n",
    "                    print(\"words do not match\", i+j, v[j], M[j,v[j]])\n",
    "                    print(\"instead the right word should be \", M[j,j])\n",
    "                    error_couples.append((i+j, v[j], M[j,v[j]], M[j,j]))\n",
    "\n",
    "            print(i, \"/\", len(prod), \"done\") if i % 50_000 == 0 else None\n",
    "    \n",
    "    dict[\"accuracy\"] = (right_values.mean(), right_values.std()) # values of the diagonal of the matrix\n",
    "    dict[\"n_errors\"] = len(error_couples) # number of errors\n",
    "\n",
    "    src.vectors = src.vectors @ W_\n",
    "    src.vectors_ngrams = src.vectors_ngrams @ W_\n",
    "    src.vectors = src.vectors / np.linalg.norm(src.vectors, axis=1).reshape(-1,1)\n",
    "    src.vectors_ngrams = src.vectors_ngrams / np.linalg.norm(src.vectors_ngrams, axis=1).reshape(-1,1)\n",
    "\n",
    "    return src, X, Y, W_, right_values, error_couples, dict\n",
    "\n",
    "            \n",
    "lang = \"af\"         \n",
    "src, X, Y, W_, right_values, error_couples, dict = find_matrix(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "\n",
    "def create_bin(lang):\n",
    "    \n",
    "    print(\"LANG\", lang)\n",
    "\n",
    "    # not aligned\n",
    "    try:\n",
    "        src = load_facebook_vectors(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.bin\") \n",
    "        print(\"Loaded fastText vectors\")\n",
    "    except:\n",
    "        print(\"Going to 'vec'\")\n",
    "        src = KeyedVectors.load_word2vec_format(f\"/data1/malto/csavelli/aligned_subwords_fasttext/wiki/wiki.{lang}.vec\")\n",
    "    \n",
    "    path = \"W/\"\n",
    "    file = f\"{lang}.pkl\"\n",
    "    with open(os.path.join(path, file), \"rb\") as f:\n",
    "        W_ = pickle.load(f)\n",
    "\n",
    "    src.vectors = src.vectors @ W_\n",
    "    src.vectors_ngrams = src.vectors_ngrams @ W_\n",
    "    src.vectors = src.vectors / np.linalg.norm(src.vectors, axis=1).reshape(-1,1)\n",
    "    src.vectors_ngrams = src.vectors_ngrams / np.linalg.norm(src.vectors_ngrams, axis=1).reshape(-1,1)\n",
    "\n",
    "    return W_, src \n",
    "\n",
    "W1, src1 = create_bin(\"af\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src2 = KeyedVectors.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin\")\n",
    "vectors_ngrams = np.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin.vectors_ngrams.npy\", allow_pickle=True)\n",
    "vectors_vocab = np.load(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.bin.vectors_vocab.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(src.vectors == src1.vectors).all(), (src.vectors_ngrams == vectors_ngrams).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonk = KeyedVectors.load(\"test\")\n",
    "bonk.vectors == src.vectors, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain.vectors = src.vectors\n",
    "plain.vectors_ngrams = src.vectors_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, X, Y, W_, right_values, error_couples, dict = find_matrix(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save src with pickle \n",
    "\n",
    "import pickle\n",
    "\n",
    "path = \"W/\"\n",
    "file = f\"{lang}.pkl\"\n",
    "\n",
    "with open(f\"test2\", \"wb\") as f:\n",
    "                pickle.dump((src), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load src with pickle\n",
    "with open(f\"test2\", \"rb\") as f:\n",
    "    bonk = pickle.load(f)\n",
    "\n",
    "(bonk.vectors == src.vectors).all(), (bonk.vectors_ngrams == src.vectors_ngrams).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"af\"\n",
    "with open(f\"/data1/malto/csavelli/aligned_subwords_fasttext/res/{lang}/wiki.{lang}.pkl\", \"rb\") as f:\n",
    "    bonk2 = pickle.load(f)\n",
    "\n",
    "(bonk2.vectors == src.vectors).all(), (bonk2.vectors_ngrams == src.vectors_ngrams).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.save(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = KeyedVectors.load(\"test\")\n",
    "vectors_ngrams = np.load(\"test.vectors_ngrams.npy\", allow_pickle=True)\n",
    "vectors_vocab = np.load(f\"test.vectors_vocab.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_ngrams.shape, vectors_vocab.shape, src.vectors_ngrams.shape, src.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vectors_vocab[0]\n",
    "\n",
    "for row in src.vectors:\n",
    "    if (row == v).all():\n",
    "        print(\"found\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.vectors_ngrams == vectors_ngrams, src.vectors == vectors_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.vectors_ngrams == vectors_ngrams, test_model.vectors == src.vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
